{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cbe08d1-bb80-47b5-9396-04ed669f43ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, max, min, count, when, rank, sum as _sum\n",
    "from pyspark.sql.functions import current_date, datediff, lit\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import DateType\n",
    "import random\n",
    "from datetime import date, timedelta\n",
    "spark = SparkSession.builder.appName(\"AdvancedEmployeeAnalytics\").getOrCreate()\n",
    "data = [\n",
    "    (\"Ananya\", \"HR\", 52000),\n",
    "    (\"Rahul\", \"Engineering\", 65000),\n",
    "    (\"Priya\", \"Engineering\", 60000),\n",
    "    (\"Zoya\", \"Marketing\", 48000),\n",
    "    (\"Karan\", \"HR\", 53000),\n",
    "    (\"Naveen\", \"Engineering\", 70000),\n",
    "    (\"Fatima\", \"Marketing\", 45000)\n",
    "]\n",
    "columns = [\"Name\", \"Department\", \"Salary\"]\n",
    "df_emp = spark.createDataFrame(data, columns)\n",
    "performance = [\n",
    "    (\"Ananya\", 2023, 4.5),\n",
    "    (\"Rahul\", 2023, 4.9),\n",
    "    (\"Priya\", 2023, 4.3),\n",
    "    (\"Zoya\", 2023, 3.8),\n",
    "    (\"Karan\", 2023, 4.1),\n",
    "    (\"Naveen\", 2023, 4.7),\n",
    "    (\"Fatima\", 2023, 3.9)\n",
    "]\n",
    "columns_perf = [\"Name\", \"Year\", \"Rating\"]\n",
    "df_perf = spark.createDataFrame(performance, columns_perf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adbbeb30-9f23-44e9-9c56-06897846979b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "GroupBy and Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d73b834d-4d6f-48ad-a709-f8a5760abc8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n| Department|AvgSalary|\n+-----------+---------+\n|         HR|  52500.0|\n|Engineering|  65000.0|\n|  Marketing|  46500.0|\n+-----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "df_emp.groupBy(\"Department\").agg(avg(\"Salary\").alias(\"AvgSalary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c680310-d5f9-4503-bc94-b89654457015",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n| Department|EmployeeCount|\n+-----------+-------------+\n|         HR|            2|\n|Engineering|            3|\n|  Marketing|            2|\n+-----------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_emp.groupBy(\"Department\").agg(count(\"*\").alias(\"EmployeeCount\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19b7731d-9723-4695-be6e-d285d6607430",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n|MaxSalary|MinSalary|\n+---------+---------+\n|    70000|    60000|\n+---------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "df_emp.filter(col(\"Department\") == \"Engineering\") \\\n",
    "      .agg(max(\"Salary\").alias(\"MaxSalary\"), min(\"Salary\").alias(\"MinSalary\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75530f37-93f0-496c-9d54-b1776c61da47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Join and Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf7e0514-51cc-4fbc-8c24-a5660cdee2d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined = df_emp.join(df_perf, on=\"Name\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e39b505-a40e-4697-bb51-ab500a6b2278",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n|  Name|Salary|Rating|\n+------+------+------+\n|Ananya| 52000|   4.5|\n|Fatima| 45000|   3.9|\n| Karan| 53000|   4.1|\n|Naveen| 70000|   4.7|\n| Priya| 60000|   4.3|\n| Rahul| 65000|   4.9|\n|  Zoya| 48000|   3.8|\n+------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df_joined.select(\"Name\", \"Salary\", \"Rating\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ef1cf0d-1b05-4bef-a371-48bd58ffc072",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+----+------+\n|  Name| Department|Salary|Year|Rating|\n+------+-----------+------+----+------+\n|Naveen|Engineering| 70000|2023|   4.7|\n| Rahul|Engineering| 65000|2023|   4.9|\n+------+-----------+------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "df_joined.filter((col(\"Rating\") > 4.5) & (col(\"Salary\") > 60000)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44d2f5fe-cead-42ef-8af1-44aaceb59bfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " Bonus Challenge: Window & Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66fbd6d5-4136-4d4d-b1d1-abe26cca312d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+----------+\n|  Name| Department|Salary|SalaryRank|\n+------+-----------+------+----------+\n|Naveen|Engineering| 70000|         1|\n| Rahul|Engineering| 65000|         2|\n| Priya|Engineering| 60000|         3|\n| Karan|         HR| 53000|         1|\n|Ananya|         HR| 52000|         2|\n|  Zoya|  Marketing| 48000|         1|\n|Fatima|  Marketing| 45000|         2|\n+------+-----------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "window_dept = Window.partitionBy(\"Department\").orderBy(col(\"Salary\").desc())\n",
    "df_ranked = df_emp.withColumn(\"SalaryRank\", rank().over(window_dept))\n",
    "df_ranked.select(\"Name\", \"Department\", \"Salary\", \"SalaryRank\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a65dc337-dc8b-42ad-afce-b7cbe67181ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+----------------+\n|  Name| Department|Salary|CumulativeSalary|\n+------+-----------+------+----------------+\n|Naveen|Engineering| 70000|           70000|\n| Rahul|Engineering| 65000|          135000|\n| Priya|Engineering| 60000|          195000|\n| Karan|         HR| 53000|           53000|\n|Ananya|         HR| 52000|          105000|\n|  Zoya|  Marketing| 48000|           48000|\n|Fatima|  Marketing| 45000|           93000|\n+------+-----------+------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_cum = df_emp.withColumn(\"CumulativeSalary\", _sum(\"Salary\").over(window_dept.rowsBetween(Window.unboundedPreceding, Window.currentRow)))\n",
    "df_cum.select(\"Name\", \"Department\", \"Salary\", \"CumulativeSalary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "495d8e2f-3f76-4805-a9c9-55b1889910b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Date Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ff94c67-93d7-4a29-9c68-b37bede8a37f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "def random_date(start_year=2020, end_year=2023):\n",
    "    start = date(start_year, 1, 1)\n",
    "    end = date(end_year, 12, 31)\n",
    "    delta = end - start\n",
    "    return start + timedelta(days=random.randint(0, delta.days))\n",
    "join_dates = [random_date() for _ in range(df_emp.count())]\n",
    "df_dates = spark.createDataFrame([(d,) for d in join_dates], [\"JoinDate\"]).withColumn(\"JoinDate\", col(\"JoinDate\").cast(DateType()))\n",
    "df_emp = df_emp.withColumn(\"row_id\", lit(1)).join(df_dates.withColumn(\"row_id\", lit(1)), \"row_id\").drop(\"row_id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4b59cb2-1195-458d-95b4-3acccad29391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------------+\n|  Name|  JoinDate|YearsWithCompany|\n+------+----------+----------------+\n|Ananya|2023-11-24|               1|\n|Ananya|2023-09-21|               1|\n|Ananya|2022-02-22|               3|\n|Ananya|2021-05-09|               4|\n|Ananya|2020-03-14|               5|\n|Ananya|2022-10-08|               2|\n|Ananya|2020-12-19|               4|\n| Rahul|2023-11-24|               1|\n| Priya|2023-11-24|               1|\n| Rahul|2023-09-21|               1|\n| Rahul|2022-02-22|               3|\n| Priya|2023-09-21|               1|\n| Priya|2022-02-22|               3|\n| Rahul|2021-05-09|               4|\n| Rahul|2020-03-14|               5|\n| Priya|2021-05-09|               4|\n| Priya|2020-03-14|               5|\n| Rahul|2022-10-08|               2|\n| Rahul|2020-12-19|               4|\n| Priya|2022-10-08|               2|\n+------+----------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_emp = df_emp.withColumn(\"YearsWithCompany\", (datediff(current_date(), col(\"JoinDate\")) / 365).cast(\"int\"))\n",
    "df_emp.select(\"Name\", \"JoinDate\", \"YearsWithCompany\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34f5f3ba-3bdf-4d62-86b1-f6b7ab33deb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Writing to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a328462-6e43-4e00-a8de-bc22b31e6b44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_emp.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/tmp/employee_data_csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a3c1d6b-16c6-4cf0-89d6-5ec999279302",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_joined.write.mode(\"overwrite\").parquet(\"/tmp/employee_performance_parquet\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "aggr and grouping",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}