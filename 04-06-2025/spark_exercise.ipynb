{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "BJoykRPRdj5r",
        "outputId": "044985f7-b02f-44fe-f470-314795204539"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7887c442a590>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d1be49262b92:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>SparkSQLExercises</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"SparkSQLExercises\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create database\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS sales_db\")\n",
        "\n",
        "# 2. Set current database\n",
        "spark.catalog.setCurrentDatabase(\"sales_db\")\n",
        "\n",
        "# 3. Create table\n",
        "spark.sql(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS product_sales (\n",
        "    ProductID INT,\n",
        "    ProductName STRING,\n",
        "    Category STRING,\n",
        "    Price DOUBLE,\n",
        "    Quantity INT,\n",
        "    SaleDate DATE\n",
        ") USING CSV\n",
        "OPTIONS ('path' '/tmp/product_sales.csv', 'header' 'true')\n",
        "\"\"\")\n",
        "\n",
        "# For environments without file persistence, we can create using a DataFrame:\n",
        "data = [\n",
        "    (1, \"Laptop\", \"Electronics\", 900.0, 2, \"2024-12-01\"),\n",
        "    (2, \"Phone\", \"Electronics\", 600.0, 1, \"2024-11-15\"),\n",
        "    (3, \"Chair\", \"Furniture\", 150.0, 4, \"2024-11-10\"),\n",
        "    (4, \"Desk\", \"Furniture\", 300.0, 2, \"2024-11-11\"),\n",
        "    (5, \"Pen\", \"Stationery\", 5.0, 10, \"2024-10-10\")\n",
        "]\n",
        "columns = [\"ProductID\", \"ProductName\", \"Category\", \"Price\", \"Quantity\", \"SaleDate\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.write.saveAsTable(\"product_sales\", mode=\"overwrite\")\n"
      ],
      "metadata": {
        "id": "9p7ezp4Ydqbp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Select all\n",
        "spark.sql(\"SELECT * FROM product_sales\").show()\n",
        "\n",
        "# 6. Price > 500\n",
        "spark.sql(\"SELECT * FROM product_sales WHERE Price > 500\").show()\n",
        "\n",
        "# 7. Total Sale Amount\n",
        "spark.sql(\"SELECT ProductName, Price, Quantity, (Price * Quantity) AS TotalAmount FROM product_sales\").show()\n",
        "\n",
        "# 8. Products per Category\n",
        "spark.sql(\"SELECT Category, COUNT(*) AS ProductCount FROM product_sales GROUP BY Category\").show()\n",
        "\n",
        "# 9. Sort by Total Sales\n",
        "spark.sql(\"SELECT ProductName, (Price * Quantity) AS Total FROM product_sales ORDER BY Total DESC\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA1BjAuFd8Ly",
        "outputId": "e8cb05e5-7f1c-473e-9b7c-940e3eb7854b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|ProductID|ProductName|   Category|Price|Quantity|  SaleDate|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|        3|      Chair|  Furniture|150.0|       4|2024-11-10|\n",
            "|        4|       Desk|  Furniture|300.0|       2|2024-11-11|\n",
            "|        5|        Pen| Stationery|  5.0|      10|2024-10-10|\n",
            "|        1|     Laptop|Electronics|900.0|       2|2024-12-01|\n",
            "|        2|      Phone|Electronics|600.0|       1|2024-11-15|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|ProductID|ProductName|   Category|Price|Quantity|  SaleDate|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|        1|     Laptop|Electronics|900.0|       2|2024-12-01|\n",
            "|        2|      Phone|Electronics|600.0|       1|2024-11-15|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "\n",
            "+-----------+-----+--------+-----------+\n",
            "|ProductName|Price|Quantity|TotalAmount|\n",
            "+-----------+-----+--------+-----------+\n",
            "|      Chair|150.0|       4|      600.0|\n",
            "|       Desk|300.0|       2|      600.0|\n",
            "|        Pen|  5.0|      10|       50.0|\n",
            "|     Laptop|900.0|       2|     1800.0|\n",
            "|      Phone|600.0|       1|      600.0|\n",
            "+-----------+-----+--------+-----------+\n",
            "\n",
            "+-----------+------------+\n",
            "|   Category|ProductCount|\n",
            "+-----------+------------+\n",
            "| Stationery|           1|\n",
            "|  Furniture|           2|\n",
            "|Electronics|           2|\n",
            "+-----------+------------+\n",
            "\n",
            "+-----------+------+\n",
            "|ProductName| Total|\n",
            "+-----------+------+\n",
            "|     Laptop|1800.0|\n",
            "|      Chair| 600.0|\n",
            "|      Phone| 600.0|\n",
            "|       Desk| 600.0|\n",
            "|        Pen|  50.0|\n",
            "+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_data = [\n",
        "    (101, \"Keyboard\", \"Electronics\", 50.0, 2),\n",
        "    (102, \"Mouse\", \"Electronics\", 25.0, 1),\n",
        "    (103, \"Notebook\", \"Stationery\", 3.0, 5)\n",
        "]\n",
        "temp_cols = [\"ProductID\", \"ProductName\", \"Category\", \"Price\", \"Quantity\"]\n",
        "temp_df = spark.createDataFrame(temp_data, temp_cols)\n",
        "\n",
        "# 11. Register temporary view\n",
        "temp_df.createOrReplaceTempView(\"temp_orders\")\n",
        "\n",
        "# 12. Query temp view\n",
        "spark.sql(\"SELECT * FROM temp_orders WHERE Quantity > 1\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4zEs7p9d_qT",
        "outputId": "56120d47-f0a2-4816-8139-16ec2b8a052a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------+-----+--------+\n",
            "|ProductID|ProductName|   Category|Price|Quantity|\n",
            "+---------+-----------+-----------+-----+--------+\n",
            "|      101|   Keyboard|Electronics| 50.0|       2|\n",
            "|      103|   Notebook| Stationery|  3.0|       5|\n",
            "+---------+-----------+-----------+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Global temp view\n",
        "temp_df.createOrReplaceGlobalTempView(\"global_orders\")\n",
        "\n",
        "# 14. Query in this or another session\n",
        "spark.sql(\"SELECT * FROM global_temp.global_orders WHERE Price > 30\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOhsFmkZd_3B",
        "outputId": "a31e56f0-a32c-463d-9be1-00f00bf98093"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------+-----+--------+\n",
            "|ProductID|ProductName|   Category|Price|Quantity|\n",
            "+---------+-----------+-----------+-----+--------+\n",
            "|      101|   Keyboard|Electronics| 50.0|       2|\n",
            "+---------+-----------+-----------+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15â€“16. Create & insert customer table\n",
        "customer_data = [\n",
        "    (1, \"Alice\", \"F\", \"New York\", \"2023-01-01\"),\n",
        "    (2, \"Bob\", \"M\", \"Chicago\", \"2023-02-01\"),\n",
        "    (3, \"Charlie\", \"M\", \"Boston\", \"2023-03-01\")\n",
        "]\n",
        "customer_cols = [\"CustomerID\", \"Name\", \"Gender\", \"City\", \"SignupDate\"]\n",
        "cust_df = spark.createDataFrame(customer_data, customer_cols)\n",
        "cust_df.write.saveAsTable(\"customer_details\", mode=\"overwrite\")\n",
        "\n",
        "# 17. Simulated Join (ProductID == CustomerID)\n",
        "spark.sql(\"\"\"\n",
        "SELECT p.ProductName, c.Name, c.City\n",
        "FROM product_sales p\n",
        "JOIN customer_details c\n",
        "ON p.ProductID = c.CustomerID\n",
        "\"\"\").show()\n",
        "\n",
        "# 18. Customers who bought more than 2 products\n",
        "spark.sql(\"\"\"\n",
        "SELECT c.Name, SUM(p.Quantity) AS TotalBought\n",
        "FROM product_sales p\n",
        "JOIN customer_details c ON p.ProductID = c.CustomerID\n",
        "GROUP BY c.Name\n",
        "HAVING SUM(p.Quantity) > 2\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyaAQ-CueMP9",
        "outputId": "998e7a8e-8baa-48cf-d6ee-e26d3a98e069"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+--------+\n",
            "|ProductName|   Name|    City|\n",
            "+-----------+-------+--------+\n",
            "|      Phone|    Bob| Chicago|\n",
            "|      Chair|Charlie|  Boston|\n",
            "|     Laptop|  Alice|New York|\n",
            "+-----------+-------+--------+\n",
            "\n",
            "+-------+-----------+\n",
            "|   Name|TotalBought|\n",
            "+-------+-----------+\n",
            "|Charlie|          4|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 19. Create view\n",
        "spark.sql(\"\"\"\n",
        "CREATE OR REPLACE VIEW sales_summary AS\n",
        "SELECT ProductName, Price, Quantity, (Price * Quantity) AS Total\n",
        "FROM product_sales\n",
        "\"\"\")\n",
        "\n",
        "# 20. Query view\n",
        "spark.sql(\"SELECT * FROM sales_summary WHERE Total > 1000\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RKgrc9WeQwi",
        "outputId": "57f52523-53ed-48af-83bb-04ddf67d9074"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+--------+------+\n",
            "|ProductName|Price|Quantity| Total|\n",
            "+-----------+-----+--------+------+\n",
            "|     Laptop|900.0|       2|1800.0|\n",
            "+-----------+-----+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 21. Drop view\n",
        "spark.sql(\"DROP VIEW IF EXISTS sales_summary\")\n",
        "\n",
        "# 22. Drop tables\n",
        "spark.sql(\"DROP TABLE IF EXISTS product_sales\")\n",
        "spark.sql(\"DROP TABLE IF EXISTS customer_details\")\n",
        "\n",
        "# 23. Drop database\n",
        "spark.sql(\"DROP DATABASE IF EXISTS sales_db CASCADE\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6xbRVz0eQ9g",
        "outputId": "0b55d6ad-4d42-48d0-fc85-52d8bcae2f57"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}